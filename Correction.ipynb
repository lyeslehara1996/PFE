{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "correction.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMBoeqSuxy7RaGJ7VTNTOwP",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/lyeslehara1996/PFE/blob/main/Correction.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qzWcU36ddcym",
        "outputId": "d9eb4a8a-3afc-4ec5-bfdd-0b334407ee5e"
      },
      "source": [
        "pip install np_utils"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting np_utils\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/b6/18/5704a782fd72727a9e63198fcc76fadb86975f45bcdf579c10f668329508/np_utils-0.5.12.1.tar.gz (61kB)\n",
            "\r\u001b[K     |█████▍                          | 10kB 16.5MB/s eta 0:00:01\r\u001b[K     |██████████▊                     | 20kB 7.7MB/s eta 0:00:01\r\u001b[K     |████████████████                | 30kB 5.0MB/s eta 0:00:01\r\u001b[K     |█████████████████████▍          | 40kB 4.6MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▊     | 51kB 2.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 61kB 2.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.0 in /usr/local/lib/python3.7/dist-packages (from np_utils) (1.19.5)\n",
            "Requirement already satisfied: future>=0.16 in /usr/local/lib/python3.7/dist-packages (from np_utils) (0.16.0)\n",
            "Building wheels for collected packages: np-utils\n",
            "  Building wheel for np-utils (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for np-utils: filename=np_utils-0.5.12.1-cp37-none-any.whl size=57133 sha256=6ead89dfecc3b51b068861871cd918f68dd1d240fd259caf7ef44440f7c552a1\n",
            "  Stored in directory: /root/.cache/pip/wheels/92/4b/81/206efd0d01330a96f3aebe5021d2d5f0b264b7ade827c306ef\n",
            "Successfully built np-utils\n",
            "Installing collected packages: np-utils\n",
            "Successfully installed np-utils-0.5.12.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yAS945MBRBBT",
        "outputId": "3e89843d-a6a4-4f83-f9d8-3ff28d63d4b9"
      },
      "source": [
        "#declaration des module \n",
        "\n",
        "import pandas as pd \n",
        "import re \n",
        "import nltk\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from keras.layers import Dropout\n",
        "\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.tokenize.toktok import ToktokTokenizer\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from nltk.tokenize import TweetTokenizer\n",
        "import string as st\n",
        "SAVEd = False\n",
        "\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Embedding, LSTM, SpatialDropout1D\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "from nltk.corpus import stopwords\n",
        "from sklearn.metrics import classification_report,confusion_matrix,accuracy_score\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.metrics import confusion_matrix,classification_report\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-Q3IEWnedmW1"
      },
      "source": [
        "from keras.utils.np_utils import to_categorical"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cEFEkcm0RmRH"
      },
      "source": [
        "df=pd.read_excel('/content/SemEval2017.xlsx')"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c8TjrvTnjTOo"
      },
      "source": [
        "netoyage de dataset\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        },
        "id": "2ae0vZmPUV3Q",
        "outputId": "41c59ef4-3646-429c-ef0f-8b95c3ccf202"
      },
      "source": [
        "df.drop(\"Unnamed: 3\", axis=1, inplace=True)\n",
        "df.drop(\"Unnamed: 4\", axis=1, inplace=True)\n",
        "df.drop(\"Unnamed: 5\", axis=1, inplace=True)\n",
        "df.drop(\"Unnamed: 6\", axis=1, inplace=True)\n",
        "df.drop(\"Unnamed: 7\", axis=1, inplace=True)\n",
        "df.drop(\"Unnamed: 8\", axis=1, inplace=True)\n",
        "df.drop(\"Unnamed: 9\", axis=1, inplace=True)\n",
        "df.drop(\"Unnamed: 10\", axis=1, inplace=True)\n",
        "df.drop(\"Unnamed: 11\", axis=1, inplace=True)\n",
        "df.drop(\"Unnamed: 12\", axis=1, inplace=True)\n",
        "df.drop(\"Unnamed: 13\", axis=1, inplace=True)\n",
        "df.drop(\"Unnamed: 14\", axis=1, inplace=True)\n",
        "df.drop(\"Unnamed: 15\", axis=1, inplace=True)\n",
        "df.head()"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>polariy</th>\n",
              "      <th>Comments</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>619950566786113024</td>\n",
              "      <td>neutral</td>\n",
              "      <td>Picturehouse's, Pink Floyd's, 'Roger Waters: T...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>619969366986235008</td>\n",
              "      <td>neutral</td>\n",
              "      <td>Order Go Set a Watchman in store or through ou...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>619971047195044992</td>\n",
              "      <td>negative</td>\n",
              "      <td>If these runway renovations at the airport pre...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>619974445185302016</td>\n",
              "      <td>neutral</td>\n",
              "      <td>If you could ask an onstage interview question...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>619987808317406976</td>\n",
              "      <td>positive</td>\n",
              "      <td>A portion of book sales from our Harper Lee/Go...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                   id  ...                                           Comments\n",
              "0  619950566786113024  ...  Picturehouse's, Pink Floyd's, 'Roger Waters: T...\n",
              "1  619969366986235008  ...  Order Go Set a Watchman in store or through ou...\n",
              "2  619971047195044992  ...  If these runway renovations at the airport pre...\n",
              "3  619974445185302016  ...  If you could ask an onstage interview question...\n",
              "4  619987808317406976  ...  A portion of book sales from our Harper Lee/Go...\n",
              "\n",
              "[5 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kMsWTh_snayA"
      },
      "source": [
        "**Prétraitement de dataSet**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "89n8Otk5jmHh"
      },
      "source": [
        "transformer les mots en miniscule\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 414
        },
        "id": "1N4tWz_uUpvz",
        "outputId": "611ee065-a427-44c3-85cf-18a8dd34b4f4"
      },
      "source": [
        "df_clean = df\n",
        "df_clean.Comments=df_clean.Comments.str.lower()\n",
        "df_clean\n",
        "\n"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>polariy</th>\n",
              "      <th>Comments</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>619950566786113024</td>\n",
              "      <td>neutral</td>\n",
              "      <td>picturehouse's, pink floyd's, 'roger waters: t...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>619969366986235008</td>\n",
              "      <td>neutral</td>\n",
              "      <td>order go set a watchman in store or through ou...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>619971047195044992</td>\n",
              "      <td>negative</td>\n",
              "      <td>if these runway renovations at the airport pre...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>619974445185302016</td>\n",
              "      <td>neutral</td>\n",
              "      <td>if you could ask an onstage interview question...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>619987808317406976</td>\n",
              "      <td>positive</td>\n",
              "      <td>a portion of book sales from our harper lee/go...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20628</th>\n",
              "      <td>681877834982232064</td>\n",
              "      <td>neutral</td>\n",
              "      <td>@shaquillehoneal from what i think you're aski...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20629</th>\n",
              "      <td>681879579129200000</td>\n",
              "      <td>positive</td>\n",
              "      <td>iran ranks 1st in liver surgeries, allah bless...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20630</th>\n",
              "      <td>681883903259357056</td>\n",
              "      <td>neutral</td>\n",
              "      <td>hours before he arrived in saudi arabia on tue...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20631</th>\n",
              "      <td>681904976860327040</td>\n",
              "      <td>negative</td>\n",
              "      <td>@vanityfair  alex kim kardashian worth how to ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20632</th>\n",
              "      <td>681910549211287040</td>\n",
              "      <td>neutral</td>\n",
              "      <td>i guess even pandora knows justin bieber is a ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>20633 rows × 3 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                       id  ...                                           Comments\n",
              "0      619950566786113024  ...  picturehouse's, pink floyd's, 'roger waters: t...\n",
              "1      619969366986235008  ...  order go set a watchman in store or through ou...\n",
              "2      619971047195044992  ...  if these runway renovations at the airport pre...\n",
              "3      619974445185302016  ...  if you could ask an onstage interview question...\n",
              "4      619987808317406976  ...  a portion of book sales from our harper lee/go...\n",
              "...                   ...  ...                                                ...\n",
              "20628  681877834982232064  ...  @shaquillehoneal from what i think you're aski...\n",
              "20629  681879579129200000  ...  iran ranks 1st in liver surgeries, allah bless...\n",
              "20630  681883903259357056  ...  hours before he arrived in saudi arabia on tue...\n",
              "20631  681904976860327040  ...  @vanityfair  alex kim kardashian worth how to ...\n",
              "20632  681910549211287040  ...  i guess even pandora knows justin bieber is a ...\n",
              "\n",
              "[20633 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eF2yqlo8ns_4"
      },
      "source": [
        "Suppression de tout les symbole  "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xhxX76ENV0g8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1248a668-a331-48e1-a099-16a9efae96ca"
      },
      "source": [
        "df_clean['Comments'] = df_clean['Comments'].apply(lambda x: re.sub(r'https?:\\/\\/\\S+', ' ', str(x)))\n",
        "df_clean['Comments'] = df_clean['Comments'].apply(lambda x: re.sub(r\"www\\.[a-z]?\\.?(com)+|[a-z]+\\.(com)\", ' ', str(x)))\n",
        "df_clean['Comments'] = df_clean['Comments'].apply(lambda x: re.sub(r'{link}', ' ', str(x)))\n",
        "df_clean['Comments'] = df_clean['Comments'].apply(lambda x: re.sub(r'&[a-z]+;', ' ', str(x)))\n",
        "df_clean['Comments'] = df_clean['Comments'].apply(lambda x: re.sub(r\"[^a-z]\", ' ', str(x)))\n",
        "df_clean['Comments'] = df_clean['Comments'].apply(lambda x: re.sub(r'@mention', ' ', str(x)))\n",
        "df_clean['Comments'] = df_clean['Comments'].apply(lambda x: \" \".join(x.lower() for x in str(x).split()  if len(x)>3 ))\n",
        "df_clean['Comments'].head()"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    picturehouse pink floyd roger waters walll ope...\n",
              "1    order watchman store through website before tu...\n",
              "2    these runway renovations airport prevent from ...\n",
              "3    could onstage interview question miss tomorrow...\n",
              "4    portion book sales from harper watchman releas...\n",
              "Name: Comments, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x_bPxU5D4VKc"
      },
      "source": [
        "df_clean['polariy'] = df_clean['polariy'].apply(lambda x: re.sub(r'https?:\\/\\/\\S+><', ' ', str(x)))\n"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PPkLYraL6uch"
      },
      "source": [
        "#Tokenization of text\n",
        "tokenizer=ToktokTokenizer()\n",
        "#Setting English stopwords\n",
        "stopword_list=nltk.corpus.stopwords.words('english')"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gbc1gHZTbBsK"
      },
      "source": [
        "Suppression de stop words\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H2ico6Il6wS2",
        "outputId": "1dba9caa-3522-4ea6-9ecc-180ff2d15eff"
      },
      "source": [
        "stop=set(stopwords.words('english'))\n",
        "print(stop)\n",
        "\n",
        "#removing the stopwords\n",
        "def remove_stopwords(text, is_lower_case=False):\n",
        "    tokens = tokenizer.tokenize(text)\n",
        "    tokens = [token.strip() for token in tokens]\n",
        "    if is_lower_case:\n",
        "        filtered_tokens = [token for token in tokens if token not in stopword_list]\n",
        "    else:\n",
        "        filtered_tokens = [token for token in tokens if token.lower() not in stopword_list]\n",
        "    filtered_text = ' '.join(filtered_tokens)    \n",
        "    return filtered_text\n",
        "#Apply function on review column\n",
        "df_clean['Comments']=df_clean['Comments'].apply(remove_stopwords)"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'there', 'd', 'above', 's', 'needn', \"hadn't\", 'have', 'when', 'all', 'ma', \"should've\", 'himself', 'being', \"wouldn't\", \"won't\", 'with', 'just', 'his', 'but', 'm', 'an', \"aren't\", 'down', 'under', 'we', 'more', 'this', 'by', \"didn't\", 'itself', 'you', \"you'd\", 'few', 'they', 'between', 'ain', 'too', 'ours', 'any', 'where', 'the', 'how', 'against', \"needn't\", 'after', 'her', 'each', 'mustn', 'for', \"shouldn't\", 'myself', \"couldn't\", 'o', \"mustn't\", 'most', 'why', \"you'll\", 'who', 'of', 'not', 'him', 'isn', 'our', 'weren', 't', 'yourself', 'off', 'some', 're', 'he', 'doing', 'can', 'theirs', 'at', \"that'll\", 'then', 'it', 'are', \"don't\", 'other', 've', 'aren', 'during', \"shan't\", 'were', \"you're\", 'a', 'while', 'once', 'wasn', 'and', 'own', 'y', 'whom', 'because', \"hasn't\", \"haven't\", 'in', \"mightn't\", 'that', 'up', 'she', 'nor', 'my', 'your', 'both', 'wouldn', 'over', 'mightn', 'was', 'hers', 'me', 'is', 'been', 'into', 'what', 'yours', 'herself', 'so', 'them', \"isn't\", 'won', 'does', 'only', \"doesn't\", 'further', 'from', 'as', 'should', 'these', 'hasn', 'such', 'their', 'having', 'didn', 'its', 'll', 'out', 'if', 'on', 'couldn', \"weren't\", 'hadn', 'doesn', \"it's\", 'shan', 'until', 'very', 'am', 'before', \"wasn't\", 'or', 'through', 'has', 'those', 'had', 'which', 'will', 'same', 'no', 'do', 'don', 'i', 'yourselves', 'about', 'than', \"you've\", 'themselves', 'be', 'here', 'again', 'now', 'ourselves', 'below', 'to', 'shouldn', \"she's\", 'haven', 'did'}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oh5-GSedq56y"
      },
      "source": [
        "Décomposition de dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c3Nq389jy8KO"
      },
      "source": [
        "reviews =  df_clean[['Comments']]\n",
        "labels =  df_clean[['polariy']]"
      ],
      "execution_count": 79,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5P3uWb15bOtj"
      },
      "source": [
        "suppression de ponctuation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xdX51Wpc3vM-"
      },
      "source": [
        "revue_sans_ponctuation=[]\n",
        "for sentence in reviews['Comments']:\n",
        "\n",
        "    revue_sans_ponctuation.append(' '.join(Word.strip(st.punctuation) for Word in sentence.split()))\n"
      ],
      "execution_count": 78,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qfvQpZLR7ado",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bf0baeee-f519-4b7b-c418-684e68f5b43e"
      },
      "source": [
        "reviews_cleaned = np.asarray(revue_sans_ponctuation)\n",
        "reviews_cleaned"
      ],
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['picturehouse pink floyd roger waters walll opening sept making waves watch trailer rolling stone look',\n",
              "       'order watchman store website tuesday half price gsaw gsawatchmanbook',\n",
              "       'runway renovations airport prevent seeing taylor swift monday blood meaning',\n",
              "       ...,\n",
              "       'hours arrived saudi arabia tuesday turkish president recep tayyip erdogan accused syria president mercilessly',\n",
              "       'vanityfair alex kardashian worth love kardashian conure',\n",
              "       'guess even pandora knows justin bieber grown condom played'],\n",
              "      dtype='<U121')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e63poSBZ43Mj"
      },
      "source": [
        "review_array = np.asarray(reviews)\n",
        "label_array = np.asarray(labels)\n",
        "\n",
        "reviews_labels = np.stack((review_array, label_array), axis = 1)"
      ],
      "execution_count": 81,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WTDo45tz7P1M",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f5cb053e-ee93-4ffe-93d8-2f75884fe799"
      },
      "source": [
        "list_index=[]\n",
        "\n",
        "for i, text in enumerate(reviews_labels[:,0:1]):\n",
        "    if(text == \"\\n\"):\n",
        "        list_index.append(i)\n",
        "\n",
        "reviews_labels = np.delete(reviews_labels, list_index, axis=0)\n",
        "reviews_labels"
      ],
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[['picturehouse pink floyd roger waters walll opening sept making waves watch trailer rolling stone look'],\n",
              "        ['neutral']],\n",
              "\n",
              "       [['order watchman store website tuesday half price gsaw gsawatchmanbook'],\n",
              "        ['neutral']],\n",
              "\n",
              "       [['runway renovations airport prevent seeing taylor swift monday blood meaning'],\n",
              "        ['negative']],\n",
              "\n",
              "       ...,\n",
              "\n",
              "       [['hours arrived saudi arabia tuesday turkish president recep tayyip erdogan accused syria president mercilessly'],\n",
              "        ['neutral']],\n",
              "\n",
              "       [['vanityfair alex kardashian worth love kardashian conure'],\n",
              "        ['negative']],\n",
              "\n",
              "       [['guess even pandora knows justin bieber grown condom played'],\n",
              "        ['neutral']]], dtype=object)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 82
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fcpgmip1bUvC"
      },
      "source": [
        "Encoder les labels multi class"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kNmRD8Ax70HE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7e5d2825-9c21-4658-b0a8-2c926308ed2f"
      },
      "source": [
        "\n",
        "\n",
        "le=LabelEncoder()\n",
        "encoded_labels= le.fit_transform( label_array)\n",
        "encoded_labels = to_categorical(encoded_labels)\n",
        "encoded_labels"
      ],
      "execution_count": 104,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/preprocessing/_label.py:251: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0., 0., 1., 0.],\n",
              "       [0., 0., 1., 0.],\n",
              "       [0., 1., 0., 0.],\n",
              "       ...,\n",
              "       [0., 0., 1., 0.],\n",
              "       [0., 1., 0., 0.],\n",
              "       [0., 0., 1., 0.]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 104
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NeYqrW6VbbXK"
      },
      "source": [
        "Déviser les donnés de test et d'entraînement"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oXgnP0xH8IC0",
        "outputId": "b7f66a6d-2ac9-47cc-823e-75d205180118"
      },
      "source": [
        "review_train, review_test, label_train, label_test = train_test_split(reviews_cleaned,encoded_labels ,test_size=0.2, random_state=42)\n",
        "\n",
        "print(review_train.shape, label_train.shape)\n",
        "print(review_test.shape, label_test.shape)\n"
      ],
      "execution_count": 105,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(16506,) (16506, 4)\n",
            "(4127,) (4127, 4)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SFWK2LN8bnB4"
      },
      "source": [
        "Encoder les reviews"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DP1DtS4eqJli"
      },
      "source": [
        "tokenizer = Tokenizer(num_words=4000)\n",
        "tokenizer.fit_on_texts(review_train)\n",
        "\n",
        "review_train = tokenizer.texts_to_sequences(review_train)\n",
        "review_test = tokenizer.texts_to_sequences(review_test)\n",
        "\n",
        "vocab_size = len(tokenizer.word_index) + 1\n",
        "\n",
        "maxlen = 100\n",
        "\n",
        "review_train = pad_sequences(review_train, padding='post', maxlen=maxlen)\n",
        "review_test = pad_sequences(review_test, padding='post', maxlen=maxlen)"
      ],
      "execution_count": 106,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vIZVXy8KqMms",
        "outputId": "148e8f9b-aca0-454f-a7a4-2c379e21d876"
      },
      "source": [
        "review_train.shape\n",
        "review_train"
      ],
      "execution_count": 107,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[100,  19,  20, ...,   0,   0,   0],\n",
              "       [ 13,  77, 526, ...,   0,   0,   0],\n",
              "       [231, 124, 128, ...,   0,   0,   0],\n",
              "       ...,\n",
              "       [ 94,  83, 529, ...,   0,   0,   0],\n",
              "       [ 55,  36, 131, ...,   0,   0,   0],\n",
              "       [568,   5,  98, ...,   0,   0,   0]], dtype=int32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 107
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j6SUrsxjbw33"
      },
      "source": [
        "Model \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tLp_FdEuqRgE"
      },
      "source": [
        "model = Sequential()\n",
        "\n",
        "model.add(LSTM(units=50, return_sequences=True, input_shape=(maxlen,3)))\n",
        "model.add(Dropout(0.2))\n",
        "\n",
        "model.add(LSTM(units=50, return_sequences=True))\n",
        "model.add(Dropout(0.2))\n",
        "\n",
        "model.add(LSTM(units=50, return_sequences=True))\n",
        "model.add(Dropout(0.2))\n",
        "\n",
        "\n",
        "model.compile(loss='categorical_crossentropy',optimizer='adam',metrics=['accuracy'])"
      ],
      "execution_count": 108,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "030V0Gn8qbE0",
        "outputId": "59dfe507-d28d-4e0a-8641-60f5bfac186c"
      },
      "source": [
        "print(model.summary())"
      ],
      "execution_count": 109,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_9\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "lstm_21 (LSTM)               (None, 100, 50)           10800     \n",
            "_________________________________________________________________\n",
            "dropout_15 (Dropout)         (None, 100, 50)           0         \n",
            "_________________________________________________________________\n",
            "lstm_22 (LSTM)               (None, 100, 50)           20200     \n",
            "_________________________________________________________________\n",
            "dropout_16 (Dropout)         (None, 100, 50)           0         \n",
            "_________________________________________________________________\n",
            "lstm_23 (LSTM)               (None, 100, 50)           20200     \n",
            "_________________________________________________________________\n",
            "dropout_17 (Dropout)         (None, 100, 50)           0         \n",
            "=================================================================\n",
            "Total params: 51,200\n",
            "Trainable params: 51,200\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 565
        },
        "id": "D1K3zZxjqgcj",
        "outputId": "510726bf-3b89-4c29-d124-b9bdce1f4301"
      },
      "source": [
        "  history=model.fit(review_train,label_train, epochs=100,batch_size=64,validation_data=(review_test,label_test))  "
      ],
      "execution_count": 110,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-110-694309b7b2ec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mhistory\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreview_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlabel_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreview_test\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlabel_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1156\u001b[0m                 _r=1):\n\u001b[1;32m   1157\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1158\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1159\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1160\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    887\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    891\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    931\u001b[0m       \u001b[0;31m# This is the first call of __call__, so we have to initialize.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    932\u001b[0m       \u001b[0minitializers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 933\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_initialize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madd_initializers_to\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitializers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    934\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    935\u001b[0m       \u001b[0;31m# At this point we know that the initialization is complete (or less\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_initialize\u001b[0;34m(self, args, kwds, add_initializers_to)\u001b[0m\n\u001b[1;32m    762\u001b[0m     self._concrete_stateful_fn = (\n\u001b[1;32m    763\u001b[0m         self._stateful_fn._get_concrete_function_internal_garbage_collected(  # pylint: disable=protected-access\n\u001b[0;32m--> 764\u001b[0;31m             *args, **kwds))\n\u001b[0m\u001b[1;32m    765\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    766\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0minvalid_creator_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0munused_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0munused_kwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_get_concrete_function_internal_garbage_collected\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   3048\u001b[0m       \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3049\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3050\u001b[0;31m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3051\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3052\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_maybe_define_function\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   3442\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3443\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmissed\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcall_context_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3444\u001b[0;31m           \u001b[0mgraph_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_graph_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3445\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprimary\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcache_key\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3446\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_create_graph_function\u001b[0;34m(self, args, kwargs, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m   3287\u001b[0m             \u001b[0marg_names\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0marg_names\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3288\u001b[0m             \u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3289\u001b[0;31m             capture_by_value=self._capture_by_value),\n\u001b[0m\u001b[1;32m   3290\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_attributes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3291\u001b[0m         \u001b[0mfunction_spec\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_spec\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mfunc_graph_from_py_func\u001b[0;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m    997\u001b[0m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moriginal_func\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_decorator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munwrap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpython_func\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    998\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 999\u001b[0;31m       \u001b[0mfunc_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpython_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mfunc_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfunc_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1000\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1001\u001b[0m       \u001b[0;31m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36mwrapped_fn\u001b[0;34m(*args, **kwds)\u001b[0m\n\u001b[1;32m    670\u001b[0m         \u001b[0;31m# the function a weak reference to itself to avoid a reference cycle.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    671\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcompile_with_xla\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 672\u001b[0;31m           \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mweak_wrapped_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__wrapped__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    673\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    674\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    984\u001b[0m           \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint:disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    985\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"ag_error_metadata\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 986\u001b[0;31m               \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mag_error_metadata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    987\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    988\u001b[0m               \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: in user code:\n\n    /usr/local/lib/python3.7/dist-packages/keras/engine/training.py:830 train_function  *\n        return step_function(self, iterator)\n    /usr/local/lib/python3.7/dist-packages/keras/engine/training.py:813 run_step  *\n        outputs = model.train_step(data)\n    /usr/local/lib/python3.7/dist-packages/keras/engine/training.py:770 train_step  *\n        y_pred = self(x, training=True)\n    /usr/local/lib/python3.7/dist-packages/keras/engine/base_layer.py:989 __call__  *\n        input_spec.assert_input_compatibility(self.input_spec, inputs, self.name)\n    /usr/local/lib/python3.7/dist-packages/keras/engine/input_spec.py:212 assert_input_compatibility  *\n        raise ValueError('Input ' + str(input_index) + ' of layer ' +\n\n    ValueError: Input 0 of layer sequential_9 is incompatible with the layer: expected ndim=3, found ndim=2. Full shape received: (None, 100)\n"
          ]
        }
      ]
    }
  ]
}