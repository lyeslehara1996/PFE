{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Essay_correction_Profipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNY+BmrQu1ZUWgSistMPHiB",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/lyeslehara1996/PFE/blob/main/Essay_correction_Profipynb.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qzWcU36ddcym",
        "outputId": "99506729-7083-4db9-ff14-728f1a23c9f5"
      },
      "source": [
        "pip install np_utils"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: np_utils in /usr/local/lib/python3.7/dist-packages (0.5.12.1)\n",
            "Requirement already satisfied: numpy>=1.0 in /usr/local/lib/python3.7/dist-packages (from np_utils) (1.19.5)\n",
            "Requirement already satisfied: future>=0.16 in /usr/local/lib/python3.7/dist-packages (from np_utils) (0.16.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yAS945MBRBBT",
        "outputId": "55577e8a-de07-4fa9-de24-c219ab538be2"
      },
      "source": [
        "#declaration des module \n",
        "\n",
        "import pandas as pd \n",
        "import re \n",
        "import nltk\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.preprocessing  import MinMaxScaler\n",
        "import numpy as np\n",
        "from keras.layers import Dropout\n",
        "\n",
        "from sklearn.preprocessing import LabelBinarizer\n",
        "from nltk.tokenize import word_tokenize,sent_tokenize\n",
        "from nltk.tokenize.toktok import ToktokTokenizer\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from nltk.tokenize import TweetTokenizer\n",
        "from nltk import FreqDist\n",
        "import string as st\n",
        "SAVEd = False\n",
        "\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Embedding, LSTM, SpatialDropout1D\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "from nltk.corpus import stopwords\n",
        "from sklearn.metrics import classification_report,confusion_matrix,accuracy_score\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.metrics import confusion_matrix,classification_report\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n"
      ],
      "execution_count": 213,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 213
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-Q3IEWnedmW1"
      },
      "source": [
        "from keras.utils.np_utils import to_categorical"
      ],
      "execution_count": 214,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cEFEkcm0RmRH"
      },
      "source": [
        "df=pd.read_excel('/content/SemEval2017.xlsx')"
      ],
      "execution_count": 215,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c8TjrvTnjTOo"
      },
      "source": [
        "netoyage de dataset\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        },
        "id": "2ae0vZmPUV3Q",
        "outputId": "a1bfea0f-ddbb-46d1-cf8e-b4d2e8dcf217"
      },
      "source": [
        "df.drop(\"Unnamed: 3\", axis=1, inplace=True)\n",
        "df.drop(\"Unnamed: 4\", axis=1, inplace=True)\n",
        "df.drop(\"Unnamed: 5\", axis=1, inplace=True)\n",
        "df.drop(\"Unnamed: 6\", axis=1, inplace=True)\n",
        "df.drop(\"Unnamed: 7\", axis=1, inplace=True)\n",
        "df.drop(\"Unnamed: 8\", axis=1, inplace=True)\n",
        "df.drop(\"Unnamed: 9\", axis=1, inplace=True)\n",
        "df.drop(\"Unnamed: 10\", axis=1, inplace=True)\n",
        "df.drop(\"Unnamed: 11\", axis=1, inplace=True)\n",
        "df.drop(\"Unnamed: 12\", axis=1, inplace=True)\n",
        "df.drop(\"Unnamed: 13\", axis=1, inplace=True)\n",
        "df.drop(\"Unnamed: 14\", axis=1, inplace=True)\n",
        "df.drop(\"Unnamed: 15\", axis=1, inplace=True)\n",
        "df.head()"
      ],
      "execution_count": 216,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>polariy</th>\n",
              "      <th>Comments</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>619950566786113024</td>\n",
              "      <td>neutral</td>\n",
              "      <td>Picturehouse's, Pink Floyd's, 'Roger Waters: T...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>619969366986235008</td>\n",
              "      <td>neutral</td>\n",
              "      <td>Order Go Set a Watchman in store or through ou...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>619971047195044992</td>\n",
              "      <td>negative</td>\n",
              "      <td>If these runway renovations at the airport pre...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>619974445185302016</td>\n",
              "      <td>neutral</td>\n",
              "      <td>If you could ask an onstage interview question...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>619987808317406976</td>\n",
              "      <td>positive</td>\n",
              "      <td>A portion of book sales from our Harper Lee/Go...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                   id  ...                                           Comments\n",
              "0  619950566786113024  ...  Picturehouse's, Pink Floyd's, 'Roger Waters: T...\n",
              "1  619969366986235008  ...  Order Go Set a Watchman in store or through ou...\n",
              "2  619971047195044992  ...  If these runway renovations at the airport pre...\n",
              "3  619974445185302016  ...  If you could ask an onstage interview question...\n",
              "4  619987808317406976  ...  A portion of book sales from our Harper Lee/Go...\n",
              "\n",
              "[5 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 216
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kMsWTh_snayA"
      },
      "source": [
        "**Prétraitement**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "89n8Otk5jmHh"
      },
      "source": [
        "transformer les mots en miniscule\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        },
        "id": "1N4tWz_uUpvz",
        "outputId": "e8a00655-b7bd-4a23-9b38-c92828994372"
      },
      "source": [
        "df_clean = df\n",
        "df_clean.Comments=df_clean.Comments.str.lower()\n",
        "df_clean.head() \n"
      ],
      "execution_count": 217,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>polariy</th>\n",
              "      <th>Comments</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>619950566786113024</td>\n",
              "      <td>neutral</td>\n",
              "      <td>picturehouse's, pink floyd's, 'roger waters: t...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>619969366986235008</td>\n",
              "      <td>neutral</td>\n",
              "      <td>order go set a watchman in store or through ou...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>619971047195044992</td>\n",
              "      <td>negative</td>\n",
              "      <td>if these runway renovations at the airport pre...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>619974445185302016</td>\n",
              "      <td>neutral</td>\n",
              "      <td>if you could ask an onstage interview question...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>619987808317406976</td>\n",
              "      <td>positive</td>\n",
              "      <td>a portion of book sales from our harper lee/go...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                   id  ...                                           Comments\n",
              "0  619950566786113024  ...  picturehouse's, pink floyd's, 'roger waters: t...\n",
              "1  619969366986235008  ...  order go set a watchman in store or through ou...\n",
              "2  619971047195044992  ...  if these runway renovations at the airport pre...\n",
              "3  619974445185302016  ...  if you could ask an onstage interview question...\n",
              "4  619987808317406976  ...  a portion of book sales from our harper lee/go...\n",
              "\n",
              "[5 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 217
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eF2yqlo8ns_4"
      },
      "source": [
        "Suppression de tout les symbole  "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xhxX76ENV0g8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 414
        },
        "outputId": "5c27943c-b68c-4c3c-c101-ece14a34c828"
      },
      "source": [
        "df_clean['Comments'] = df_clean['Comments'].apply(lambda x: re.sub(r'https?:\\/\\/\\S+', ' ', str(x)))\n",
        "df_clean['Comments'] = df_clean['Comments'].apply(lambda x: re.sub(r\"www\\.[a-z]?\\.?(com)+|[a-z]+\\.(com)\", ' ', x))\n",
        "df_clean['Comments'] = df_clean['Comments'].apply(lambda x: re.sub(r'{link}', ' ', x))\n",
        "df_clean['Comments'] = df_clean['Comments'].apply(lambda x: re.sub(r'&[a-z]+;', ' ', str(x)))\n",
        "df_clean['Comments'] = df_clean['Comments'].apply(lambda x: re.sub(r\"[^a-z]\", ' ', str(x)))\n",
        "df_clean['Comments'] = df_clean['Comments'].apply(lambda x: re.sub(r'@mention', ' ', x))\n",
        "df_clean['Comments'] = df_clean['Comments'].apply(lambda x: \" \".join(x.lower() for x in str(x).split()  if len(x)>2 ))\n",
        "df_clean"
      ],
      "execution_count": 218,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>polariy</th>\n",
              "      <th>Comments</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>619950566786113024</td>\n",
              "      <td>neutral</td>\n",
              "      <td>picturehouse pink floyd roger waters the walll...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>619969366986235008</td>\n",
              "      <td>neutral</td>\n",
              "      <td>order set watchman store through our website b...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>619971047195044992</td>\n",
              "      <td>negative</td>\n",
              "      <td>these runway renovations the airport prevent f...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>619974445185302016</td>\n",
              "      <td>neutral</td>\n",
              "      <td>you could ask onstage interview question miss ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>619987808317406976</td>\n",
              "      <td>positive</td>\n",
              "      <td>portion book sales from our harper lee set wat...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20628</th>\n",
              "      <td>681877834982232064</td>\n",
              "      <td>neutral</td>\n",
              "      <td>shaquillehoneal from what think you asking ord...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20629</th>\n",
              "      <td>681879579129200000</td>\n",
              "      <td>positive</td>\n",
              "      <td>iran ranks liver surgeries allah bless the cou...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20630</th>\n",
              "      <td>681883903259357056</td>\n",
              "      <td>neutral</td>\n",
              "      <td>hours before arrived saudi arabia tuesday turk...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20631</th>\n",
              "      <td>681904976860327040</td>\n",
              "      <td>negative</td>\n",
              "      <td>vanityfair alex kim kardashian worth how love ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20632</th>\n",
              "      <td>681910549211287040</td>\n",
              "      <td>neutral</td>\n",
              "      <td>guess even pandora knows justin bieber grown t...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>20633 rows × 3 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                       id  ...                                           Comments\n",
              "0      619950566786113024  ...  picturehouse pink floyd roger waters the walll...\n",
              "1      619969366986235008  ...  order set watchman store through our website b...\n",
              "2      619971047195044992  ...  these runway renovations the airport prevent f...\n",
              "3      619974445185302016  ...  you could ask onstage interview question miss ...\n",
              "4      619987808317406976  ...  portion book sales from our harper lee set wat...\n",
              "...                   ...  ...                                                ...\n",
              "20628  681877834982232064  ...  shaquillehoneal from what think you asking ord...\n",
              "20629  681879579129200000  ...  iran ranks liver surgeries allah bless the cou...\n",
              "20630  681883903259357056  ...  hours before arrived saudi arabia tuesday turk...\n",
              "20631  681904976860327040  ...  vanityfair alex kim kardashian worth how love ...\n",
              "20632  681910549211287040  ...  guess even pandora knows justin bieber grown t...\n",
              "\n",
              "[20633 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 218
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x_bPxU5D4VKc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c515023a-32f8-4dac-d8a0-130a91af0925"
      },
      "source": [
        "df_clean['polariy'] = df_clean['polariy'].apply(lambda x: re.sub(r'https?:\\/\\/\\S+><', ' ', str(x)))\n",
        "df_clean['polariy']"
      ],
      "execution_count": 219,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0         neutral\n",
              "1         neutral\n",
              "2        negative\n",
              "3         neutral\n",
              "4        positive\n",
              "           ...   \n",
              "20628     neutral\n",
              "20629    positive\n",
              "20630     neutral\n",
              "20631    negative\n",
              "20632     neutral\n",
              "Name: polariy, Length: 20633, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 219
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PPkLYraL6uch"
      },
      "source": [
        "#Tokenization of text\n",
        "tokenizer=ToktokTokenizer()\n",
        "#Setting English stopwords\n",
        "stopword_list=nltk.corpus.stopwords.words('english')"
      ],
      "execution_count": 195,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H2ico6Il6wS2",
        "outputId": "14706ec3-4336-4aba-cae5-5ad5f8024846"
      },
      "source": [
        "stop=set(stopwords.words('english'))\n",
        "print(stop)\n",
        "\n",
        "#removing the stopwords\n",
        "def remove_stopwords(text, is_lower_case=False):\n",
        "    tokens = tokenizer.tokenize(text)\n",
        "    tokens = [token.strip() for token in tokens]\n",
        "    if is_lower_case:\n",
        "        filtered_tokens = [token for token in tokens if token not in stopword_list]\n",
        "    else:\n",
        "        filtered_tokens = [token for token in tokens if token.lower() not in stopword_list]\n",
        "    filtered_text = ' '.join(filtered_tokens)    \n",
        "    return filtered_text\n",
        "#Apply function on review column\n",
        "df_clean['Comments']=df_clean['Comments'].apply(remove_stopwords)"
      ],
      "execution_count": 220,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'our', 'too', 'myself', 'against', 'more', 'who', \"that'll\", 'were', 'has', 'have', \"shan't\", 'into', 'you', 'am', 'doesn', 'a', \"couldn't\", \"haven't\", 'this', 'from', \"should've\", 'up', 'hers', 'been', 'below', 'to', 'hasn', 'was', 'there', 'an', 'shan', 'such', \"you'll\", 'when', 'of', 'by', 'with', \"don't\", 'again', 'same', 'about', 'shouldn', 'most', 'did', 'is', 'mightn', 'his', 'mustn', 've', 'so', 'just', 'should', 'whom', 'yourself', 'yourselves', 'him', 'll', 'above', \"won't\", 'that', 'under', 'couldn', 'those', 'we', 'here', 'as', \"isn't\", 'or', 'and', 'ours', \"mightn't\", 'over', \"didn't\", 'needn', 'itself', 'be', 'than', 'y', 'ma', 'then', 'won', 'aren', 'some', 's', \"hadn't\", 'm', 'while', 'he', 'they', 'only', 'these', 'down', 'not', 'her', \"you're\", \"you've\", 're', 'themselves', 'wasn', \"she's\", 'theirs', \"aren't\", 'few', 't', 'all', 'because', \"shouldn't\", 'do', 'yours', \"hasn't\", \"it's\", 'didn', 'weren', 'are', 'out', 'o', 'my', 'having', 'own', 'doing', 'ourselves', \"wouldn't\", \"needn't\", 'what', 'nor', 'both', 'don', 'but', 'i', 'each', \"mustn't\", 'me', 'at', 'its', 'any', 'does', 'off', 'on', 'haven', 'them', 'the', 'she', 'hadn', 'for', 'during', 'after', 'until', 'where', 'no', 'once', 'your', \"doesn't\", 'isn', 'can', \"you'd\", 'had', 'if', 'ain', 'why', 'it', 'before', 'their', 'will', 'how', 'other', \"weren't\", 'between', 'further', 'wouldn', 'which', 'herself', 'd', \"wasn't\", 'being', 'in', 'himself', 'through', 'very', 'now'}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oh5-GSedq56y"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c3Nq389jy8KO",
        "outputId": "4bfea96c-b704-4463-8099-907c1de8b986"
      },
      "source": [
        "reviews =  df_clean['Comments']\n",
        "labels =  df_clean['polariy']\n",
        "reviews"
      ],
      "execution_count": 258,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0        picturehouse pink floyd roger waters walll ope...\n",
              "1        order set watchman store website tuesday get h...\n",
              "2        runway renovations airport prevent seeing tayl...\n",
              "3        could ask onstage interview question miss usa ...\n",
              "4        portion book sales harper lee set watchman rel...\n",
              "                               ...                        \n",
              "20628    shaquillehoneal think asking order future drak...\n",
              "20629       iran ranks liver surgeries allah bless country\n",
              "20630    hours arrived saudi arabia tuesday turkish pre...\n",
              "20631    vanityfair alex kim kardashian worth love kim ...\n",
              "20632    guess even pandora knows justin bieber grown c...\n",
              "Name: Comments, Length: 20633, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 258
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pl1lmes7XFGe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "81e25ec7-486b-4167-ebd4-f1603570cdd4"
      },
      "source": [
        "reviews"
      ],
      "execution_count": 259,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0        picturehouse pink floyd roger waters walll ope...\n",
              "1        order set watchman store website tuesday get h...\n",
              "2        runway renovations airport prevent seeing tayl...\n",
              "3        could ask onstage interview question miss usa ...\n",
              "4        portion book sales harper lee set watchman rel...\n",
              "                               ...                        \n",
              "20628    shaquillehoneal think asking order future drak...\n",
              "20629       iran ranks liver surgeries allah bless country\n",
              "20630    hours arrived saudi arabia tuesday turkish pre...\n",
              "20631    vanityfair alex kim kardashian worth love kim ...\n",
              "20632    guess even pandora knows justin bieber grown c...\n",
              "Name: Comments, Length: 20633, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 259
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s6ji6ZeskK_Q",
        "outputId": "9efe4f73-b06b-4f77-a937-d7192f668fb5"
      },
      "source": [
        "labels"
      ],
      "execution_count": 260,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0         neutral\n",
              "1         neutral\n",
              "2        negative\n",
              "3         neutral\n",
              "4        positive\n",
              "           ...   \n",
              "20628     neutral\n",
              "20629    positive\n",
              "20630     neutral\n",
              "20631    negative\n",
              "20632     neutral\n",
              "Name: polariy, Length: 20633, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 260
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xdX51Wpc3vM-"
      },
      "source": [
        "revue_sans_ponctuation=[]\n",
        "\n",
        "for sentence in reviews:\n",
        "    revue_sans_ponctuation.append(' '.join(Word.strip(st.punctuation) for Word in sentence.split()))"
      ],
      "execution_count": 261,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qfvQpZLR7ado",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b218f6f3-467d-423d-f616-249335d03c84"
      },
      "source": [
        "reviews_cleaned = np.asarray(revue_sans_ponctuation)\n",
        "reviews_cleaned"
      ],
      "execution_count": 262,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['picturehouse pink floyd roger waters walll opening sept making waves watch trailer rolling stone look',\n",
              "       'order set watchman store website tuesday get half price gsaw gsawatchmanbook',\n",
              "       'runway renovations airport prevent seeing taylor swift monday bad blood new meaning',\n",
              "       ...,\n",
              "       'hours arrived saudi arabia tuesday turkish president recep tayyip erdogan accused syria president mercilessly',\n",
              "       'vanityfair alex kim kardashian worth love kim kardashian bad sun conure',\n",
              "       'guess even pandora knows justin bieber grown condom played'],\n",
              "      dtype='<U125')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 262
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e63poSBZ43Mj"
      },
      "source": [
        "review_array = np.asarray(reviews)\n",
        "label_array = np.asarray(labels)\n",
        "\n",
        "reviews_labels = np.stack((review_array, label_array), axis = 1)\n"
      ],
      "execution_count": 263,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WTDo45tz7P1M",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4121133f-34bf-4077-b4cd-b39080c1cf50"
      },
      "source": [
        "list_index=[]\n",
        "\n",
        "for i, text in enumerate(reviews_labels[:,0:1]):\n",
        "    if(text == \"\\n\"):\n",
        "        list_index.append(i)\n",
        "\n",
        "reviews_labels = np.delete(reviews_labels, list_index, axis=0)\n",
        "reviews_labels"
      ],
      "execution_count": 264,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([['picturehouse pink floyd roger waters walll opening sept making waves watch trailer rolling stone look',\n",
              "        'neutral'],\n",
              "       ['order set watchman store website tuesday get half price gsaw gsawatchmanbook',\n",
              "        'neutral'],\n",
              "       ['runway renovations airport prevent seeing taylor swift monday bad blood new meaning',\n",
              "        'negative'],\n",
              "       ...,\n",
              "       ['hours arrived saudi arabia tuesday turkish president recep tayyip erdogan accused syria president mercilessly',\n",
              "        'neutral'],\n",
              "       ['vanityfair alex kim kardashian worth love kim kardashian bad sun conure',\n",
              "        'negative'],\n",
              "       ['guess even pandora knows justin bieber grown condom played',\n",
              "        'neutral']], dtype=object)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 264
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kNmRD8Ax70HE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0cfb5623-35d3-436b-ef70-67ee43a2307b"
      },
      "source": [
        "encoder = LabelEncoder()\n",
        "encoder.fit(label_array)\n",
        "encoded_labels = encoder.transform(label_array)\n",
        "# encoded_labels = to_categorical(encoded_labels)\n",
        "encoded_labels"
      ],
      "execution_count": 294,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([2, 2, 1, ..., 2, 1, 2])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 294
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oXgnP0xH8IC0",
        "outputId": "36051f5b-4464-4571-a623-62566c7aa5b3"
      },
      "source": [
        "review_train, review_test, label_train, label_test = train_test_split(reviews, encoded_labels,test_size=0.2, train_size=0.8, random_state=42)\n",
        "\n",
        "print(review_train.shape, label_train.shape)\n",
        "print(review_test.shape, label_test.shape)"
      ],
      "execution_count": 295,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(16506,) (16506,)\n",
            "(4127,) (4127,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DP1DtS4eqJli"
      },
      "source": [
        "tokenizer = Tokenizer(num_words=4000)\n",
        "tokenizer.fit_on_texts(review_train)\n",
        "\n",
        "review_train = tokenizer.texts_to_sequences(review_train)\n",
        "review_test = tokenizer.texts_to_sequences(review_test)\n",
        "\n",
        "vocab_size = len(tokenizer.word_index) + 1\n",
        "\n",
        "maxlen = 100\n",
        "\n",
        "review_train = pad_sequences(review_train, padding='post', maxlen=maxlen)\n",
        "review_test = pad_sequences(review_test, padding='post', maxlen=maxlen)"
      ],
      "execution_count": 296,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vIZVXy8KqMms",
        "outputId": "0f8e267c-e25b-48f0-e50c-b1e1a22eba09"
      },
      "source": [
        "review_train\n"
      ],
      "execution_count": 289,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[132,  25,  27, ...,   0,   0,   0],\n",
              "       [ 19,  99, 610, ...,   0,   0,   0],\n",
              "       [376, 277, 156, ...,   0,   0,   0],\n",
              "       ...,\n",
              "       [125, 106, 613, ...,   0,   0,   0],\n",
              "       [ 70,  49,  30, ...,   0,   0,   0],\n",
              "       [ 11, 662,   8, ...,   0,   0,   0]], dtype=int32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 289
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tLp_FdEuqRgE"
      },
      "source": [
        "\n",
        "model = Sequential()\n",
        "\n",
        "model.add(LSTM(units=50, return_sequences=True, input_shape=(maxlen,3)))\n",
        "model.add(Dropout(0.2))\n",
        "\n",
        "model.add(LSTM(units=50, return_sequences=True))\n",
        "model.add(Dropout(0.2))\n",
        "\n",
        "model.add(LSTM(units=50, return_sequences=True))\n",
        "model.add(Dropout(0.2))\n",
        "\n",
        "model.compile(loss='categorical_crossentropy',optimizer='adam',metrics=['accuracy'])"
      ],
      "execution_count": 305,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "030V0Gn8qbE0",
        "outputId": "8bbb519d-d3fa-484d-d56c-a4f5812cd65b"
      },
      "source": [
        "print(model.summary())"
      ],
      "execution_count": 306,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_14\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "lstm_19 (LSTM)               (None, 100, 50)           10800     \n",
            "_________________________________________________________________\n",
            "dropout_12 (Dropout)         (None, 100, 50)           0         \n",
            "_________________________________________________________________\n",
            "lstm_20 (LSTM)               (None, 100, 50)           20200     \n",
            "_________________________________________________________________\n",
            "dropout_13 (Dropout)         (None, 100, 50)           0         \n",
            "_________________________________________________________________\n",
            "lstm_21 (LSTM)               (None, 100, 50)           20200     \n",
            "_________________________________________________________________\n",
            "dropout_14 (Dropout)         (None, 100, 50)           0         \n",
            "=================================================================\n",
            "Total params: 51,200\n",
            "Trainable params: 51,200\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 565
        },
        "id": "D1K3zZxjqgcj",
        "outputId": "ad9ebfc7-76f5-47d7-db73-a871f39e40af"
      },
      "source": [
        "history=model.fit(review_train, label_train,batch_size=128, epochs=10, verbose=1,validation_data=(review_test, label_test))\n"
      ],
      "execution_count": 307,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-307-7d131fa99242>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mhistory\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreview_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m128\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreview_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1156\u001b[0m                 _r=1):\n\u001b[1;32m   1157\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1158\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1159\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1160\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    887\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    891\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    931\u001b[0m       \u001b[0;31m# This is the first call of __call__, so we have to initialize.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    932\u001b[0m       \u001b[0minitializers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 933\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_initialize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madd_initializers_to\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitializers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    934\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    935\u001b[0m       \u001b[0;31m# At this point we know that the initialization is complete (or less\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_initialize\u001b[0;34m(self, args, kwds, add_initializers_to)\u001b[0m\n\u001b[1;32m    762\u001b[0m     self._concrete_stateful_fn = (\n\u001b[1;32m    763\u001b[0m         self._stateful_fn._get_concrete_function_internal_garbage_collected(  # pylint: disable=protected-access\n\u001b[0;32m--> 764\u001b[0;31m             *args, **kwds))\n\u001b[0m\u001b[1;32m    765\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    766\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0minvalid_creator_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0munused_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0munused_kwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_get_concrete_function_internal_garbage_collected\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   3048\u001b[0m       \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3049\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3050\u001b[0;31m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3051\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3052\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_maybe_define_function\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   3442\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3443\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmissed\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcall_context_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3444\u001b[0;31m           \u001b[0mgraph_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_graph_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3445\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprimary\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcache_key\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3446\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_create_graph_function\u001b[0;34m(self, args, kwargs, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m   3287\u001b[0m             \u001b[0marg_names\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0marg_names\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3288\u001b[0m             \u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3289\u001b[0;31m             capture_by_value=self._capture_by_value),\n\u001b[0m\u001b[1;32m   3290\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_attributes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3291\u001b[0m         \u001b[0mfunction_spec\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_spec\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mfunc_graph_from_py_func\u001b[0;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m    997\u001b[0m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moriginal_func\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_decorator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munwrap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpython_func\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    998\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 999\u001b[0;31m       \u001b[0mfunc_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpython_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mfunc_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfunc_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1000\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1001\u001b[0m       \u001b[0;31m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36mwrapped_fn\u001b[0;34m(*args, **kwds)\u001b[0m\n\u001b[1;32m    670\u001b[0m         \u001b[0;31m# the function a weak reference to itself to avoid a reference cycle.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    671\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcompile_with_xla\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 672\u001b[0;31m           \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mweak_wrapped_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__wrapped__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    673\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    674\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    984\u001b[0m           \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint:disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    985\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"ag_error_metadata\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 986\u001b[0;31m               \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mag_error_metadata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    987\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    988\u001b[0m               \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: in user code:\n\n    /usr/local/lib/python3.7/dist-packages/keras/engine/training.py:830 train_function  *\n        return step_function(self, iterator)\n    /usr/local/lib/python3.7/dist-packages/keras/engine/training.py:813 run_step  *\n        outputs = model.train_step(data)\n    /usr/local/lib/python3.7/dist-packages/keras/engine/training.py:770 train_step  *\n        y_pred = self(x, training=True)\n    /usr/local/lib/python3.7/dist-packages/keras/engine/base_layer.py:989 __call__  *\n        input_spec.assert_input_compatibility(self.input_spec, inputs, self.name)\n    /usr/local/lib/python3.7/dist-packages/keras/engine/input_spec.py:212 assert_input_compatibility  *\n        raise ValueError('Input ' + str(input_index) + ' of layer ' +\n\n    ValueError: Input 0 of layer sequential_14 is incompatible with the layer: expected ndim=3, found ndim=2. Full shape received: (None, 100)\n"
          ]
        }
      ]
    }
  ]
}